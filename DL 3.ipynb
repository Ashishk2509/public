{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ynIBzbZkCAq7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19d0add4-2a52-4f54-d018-b6abe8267915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  124 253 255  63   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  96\n",
            "  244 251 253  62   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 127\n",
            "  251 251 253  62   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68 236\n",
            "  251 211  31   8   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60 228 251\n",
            "  251  94   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 253 253\n",
            "  189   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  20 253 251 235\n",
            "   66   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  32 205 253 251 126\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 104 251 253 184  15\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  80 240 251 193  23   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  32 253 253 253 159   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 151 251 251 251  39   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  48 221 251 251 172   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 234 251 251 196  12   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 253 251 251  89   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 159 255 253 253  31   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  48 228 253 247 140   8   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  64 251 253 220   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  64 251 253 220   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  24 193 253 220   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "plt.imshow(x_train[3], cmap='gray')\n",
        "plt.show()\n",
        "print(x_train[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB-4dhrZCvAU",
        "outputId": "9f98f934-f3ab-4993-fca1-fcd107db8e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train shape\", x_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", x_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ONa3VCXnDdg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b25fd4-8e41-47d5-baf8-8ae0ab57a0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 8s 5ms/step - loss: 0.2526 - accuracy: 0.9231 - val_loss: 0.1016 - val_accuracy: 0.9683\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1042 - accuracy: 0.9681 - val_loss: 0.0840 - val_accuracy: 0.9733\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0759 - accuracy: 0.9769 - val_loss: 0.0696 - val_accuracy: 0.9777\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 0.0676 - val_accuracy: 0.9797\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.0625 - val_accuracy: 0.9820\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9873 - val_loss: 0.0603 - val_accuracy: 0.9827\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 0.0693 - val_accuracy: 0.9810\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0279 - accuracy: 0.9906 - val_loss: 0.0664 - val_accuracy: 0.9825\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0635 - val_accuracy: 0.9832\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0570 - val_accuracy: 0.9846\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0678 - val_accuracy: 0.9838\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0611 - val_accuracy: 0.9836\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0731 - val_accuracy: 0.9841\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0652 - val_accuracy: 0.9853\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0685 - val_accuracy: 0.9852\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0736 - val_accuracy: 0.9849\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0821 - val_accuracy: 0.9837\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.0760 - val_accuracy: 0.9849\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0697 - val_accuracy: 0.9845\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0825 - val_accuracy: 0.9833\n"
          ]
        }
      ],
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32') # use 32-bit precision when training a neural network, so at one point the training data will have to be converted to 32 bit floats. Since the dataset fits easily in RAM, we might as well convert to float immediately.\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255  # Each image has Intensity from 0 to 255\n",
        "x_test /= 255\n",
        "num_classes = int(10)\n",
        "y_train = np.eye(num_classes)[y_train]\n",
        "y_test = np.eye(num_classes)[y_test]\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax')) \n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1, \n",
        "                    validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d78yV9sUD689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7ba2fb-5da5-43dd-a876-e4715d5fb404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.08250973373651505\n",
            "Test accuracy: 0.983299970626831\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}